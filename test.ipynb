{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "from src.exp_logger import logger\n",
    "\n",
    "import pyterrier as pt  # type: ignore\n",
    "\n",
    "from src.load_index import setup_system\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"settings.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jueri/miniconda3/envs/LongEval/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-08 21:56:53.993417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 21:56:54.793209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jueri/dev/LongEval/test.ipynb Zelle 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jueri/dev/LongEval/test.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyterrier_colbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mranking\u001b[39;00m \u001b[39mimport\u001b[39;00m ColBERTFactory\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jueri/dev/LongEval/test.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pytcolbert \u001b[39m=\u001b[39m ColBERTFactory(\u001b[39mNone\u001b[39;49;00m, \u001b[39m\"\u001b[39;49m\u001b[39mdata/index/index_WT_colBERT\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mWT_colbert\u001b[39;49m\u001b[39m\"\u001b[39;49m, faiss_partitions\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jueri/dev/LongEval/test.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dense_e2e \u001b[39m=\u001b[39m pytcolbert\u001b[39m.\u001b[39mend_to_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier_colbert/ranking.py:503\u001b[0m, in \u001b[0;36mColBERTFactory.__init__\u001b[0;34m(self, colbert_model, index_root, index_name, faiss_partitions, memtype, faisstype, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    495\u001b[0m         colbert_model : Union[\u001b[39mstr\u001b[39m, Tuple[colbert\u001b[39m.\u001b[39mmodeling\u001b[39m.\u001b[39mcolbert\u001b[39m.\u001b[39mColBERT, \u001b[39mdict\u001b[39m]], \n\u001b[1;32m    496\u001b[0m         index_root : \u001b[39mstr\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m         faisstype\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmem\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    501\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 503\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(colbert_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_faissnn \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier_colbert/ranking.py:242\u001b[0m, in \u001b[0;36mColBERTModelOnlyFactory.__init__\u001b[0;34m(self, colbert_model, gpu, mask_punctuation, dim)\u001b[0m\n\u001b[1;32m    240\u001b[0m     args\u001b[39m.\u001b[39mcolbert, args\u001b[39m.\u001b[39mcheckpoint \u001b[39m=\u001b[39m load_model(args)\n\u001b[1;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(colbert_model, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m    243\u001b[0m     args\u001b[39m.\u001b[39mcolbert, args\u001b[39m.\u001b[39mcheckpoint \u001b[39m=\u001b[39m colbert_model\n\u001b[1;32m    244\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcolbert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolbert\u001b[39;00m \u001b[39mimport\u001b[39;00m ColBERT\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyterrier_colbert.ranking import ColBERTFactory\n",
    "pytcolbert = ColBERTFactory(None, \"data/index/index_WT_colBERT\", \"WT_colbert\", faiss_partitions=100)\n",
    "dense_e2e = pytcolbert.end_to_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pt.io.read_topics(config[\"WT\"][\"train\"][\"topics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q06223196</td>\n",
       "      <td>car shelter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q062228</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q062287</td>\n",
       "      <td>antivirus comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q06223261</td>\n",
       "      <td>free antivirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q062291</td>\n",
       "      <td>orange antivirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>q062224914</td>\n",
       "      <td>tax garden shed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>q062224961</td>\n",
       "      <td>land of france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>q062225030</td>\n",
       "      <td>find my training pole job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>q062225194</td>\n",
       "      <td>gpl car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>q062225197</td>\n",
       "      <td>cheapest car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qid                      query\n",
       "0     q06223196                car shelter\n",
       "1       q062228                    airport\n",
       "2       q062287       antivirus comparison\n",
       "3     q06223261             free antivirus\n",
       "4       q062291           orange antivirus\n",
       "..          ...                        ...\n",
       "667  q062224914            tax garden shed\n",
       "668  q062224961             land of france\n",
       "669  q062225030  find my training pole job\n",
       "670  q062225194                    gpl car\n",
       "671  q062225197               cheapest car\n",
       "\n",
       "[672 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN: increase temp memory to avoid cudaMalloc, or decrease query/add size (alloc 2325624960 B, highwater 0 B)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in void faiss::gpu::allocMemorySpaceV(faiss::gpu::MemorySpace, void**, size_t) at gpu/utils/MemorySpace.cpp:26: Error: 'err == cudaSuccess' failed: failed to cudaMalloc 2325624960 bytes (error 2 out of memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jueri/dev/LongEval/test.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jueri/dev/LongEval/test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m dense_e2e(topics\u001b[39m.\u001b[39;49mhead(\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier/transformer.py:223\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m    Sets up a default method for every transformer, which is aliased to transform() (for DataFrames)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m    or transform_iter() (for iterable dictionaries) depending on the type of input. \u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39minput\u001b[39m, pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    224\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_iter(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier/apply_base.py:254\u001b[0m, in \u001b[0;36mApplyGenericTransformer.transform\u001b[0;34m(self, inputRes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, inputRes):\n\u001b[1;32m    252\u001b[0m     \u001b[39m# no batching\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(inputRes)\n\u001b[1;32m    256\u001b[0m     \u001b[39m# batching\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/pyterrier_colbert/ranking.py:661\u001b[0m, in \u001b[0;36mColBERTFactory.set_retrieve.<locals>._single_retrieve\u001b[0;34m(queries_df)\u001b[0m\n\u001b[1;32m    659\u001b[0m     Q, ids, masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39minference\u001b[39m.\u001b[39mqueryFromText([query], bsize\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, with_ids\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    660\u001b[0m Q_f \u001b[39m=\u001b[39m Q[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m, :, :]\n\u001b[0;32m--> 661\u001b[0m all_pids \u001b[39m=\u001b[39m faiss_index\u001b[39m.\u001b[39;49mretrieve(faiss_depth, Q_f, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    662\u001b[0m Q_cpu \u001b[39m=\u001b[39m Q[\u001b[39m0\u001b[39m, :, :]\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    663\u001b[0m \u001b[39mfor\u001b[39;00m passage_ids \u001b[39min\u001b[39;00m all_pids:\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/colbert/ranking/faiss_index.py:68\u001b[0m, in \u001b[0;36mFaissIndex.retrieve\u001b[0;34m(self, faiss_depth, Q, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve\u001b[39m(\u001b[39mself\u001b[39m, faiss_depth, Q, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 68\u001b[0m     embedding_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqueries_to_embedding_ids(faiss_depth, Q, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     69\u001b[0m     pids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ids_to_pids(embedding_ids, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_range \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/colbert/ranking/faiss_index.py:94\u001b[0m, in \u001b[0;36mFaissIndex.queries_to_embedding_ids\u001b[0;34m(self, faiss_depth, Q, verbose)\u001b[0m\n\u001b[1;32m     91\u001b[0m     print_message(\u001b[39m\"\u001b[39m\u001b[39m#> Searching from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(offset, endpos), condition\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m     93\u001b[0m     some_Q_faiss \u001b[39m=\u001b[39m Q_faiss[offset:endpos]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> 94\u001b[0m     _, some_embedding_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfaiss_index\u001b[39m.\u001b[39;49msearch(some_Q_faiss, faiss_depth)\n\u001b[1;32m     95\u001b[0m     embeddings_ids\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mfrom_numpy(some_embedding_ids))\n\u001b[1;32m     97\u001b[0m embedding_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(embeddings_ids)\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/faiss/__init__.py:164\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k)\u001b[0m\n\u001b[1;32m    162\u001b[0m distances \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n, k), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    163\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n, k), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n\u001b[0;32m--> 164\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_c(n, swig_ptr(x),\n\u001b[1;32m    165\u001b[0m               k, swig_ptr(distances),\n\u001b[1;32m    166\u001b[0m               swig_ptr(labels))\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m distances, labels\n",
      "File \u001b[0;32m~/miniconda3/envs/LongEval/lib/python3.8/site-packages/faiss/swigfaiss.py:4196\u001b[0m, in \u001b[0;36mGpuIndex.search\u001b[0;34m(self, n, x, k, distances, labels)\u001b[0m\n\u001b[1;32m   4195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch\u001b[39m(\u001b[39mself\u001b[39m, n, x, k, distances, labels):\n\u001b[0;32m-> 4196\u001b[0m     \u001b[39mreturn\u001b[39;00m _swigfaiss\u001b[39m.\u001b[39;49mGpuIndex_search(\u001b[39mself\u001b[39;49m, n, x, k, distances, labels)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in void faiss::gpu::allocMemorySpaceV(faiss::gpu::MemorySpace, void**, size_t) at gpu/utils/MemorySpace.cpp:26: Error: 'err == cudaSuccess' failed: failed to cudaMalloc 2325624960 bytes (error 2 out of memory)"
     ]
    }
   ],
   "source": [
    "results = dense_e2e(topics.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('LongEval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb915a841106d17bab6c0e433d807167dd40c228f7e5885474f2fcf8f68fafdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
