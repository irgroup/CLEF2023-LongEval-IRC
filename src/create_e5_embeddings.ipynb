{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.exp_logger import logger\n",
    "\n",
    "import pyterrier as pt  # type: ignore\n",
    "\n",
    "from src.load_index import setup_system, tag\n",
    "import torch \n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "with open(\"../settings.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"../\"+config[\"WT\"][\"docs\"].replace(\"Trec\", \"Json\")\n",
    "index_dir = \"../data/index/e5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-small')\n",
    "model = AutoModel.from_pretrained('intfloat/e5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare model for gpu use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calc_embeddings(texts, mode='passage'):\n",
    "  input_texts = [f\"{mode}: {text}\" for text in texts]\n",
    "  batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "  for key, val in batch_dict.items():\n",
    "    batch_dict[key] = batch_dict[key].cuda(non_blocking=True)\n",
    "  \n",
    "  outputs = model(**batch_dict)\n",
    "  embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "  return embeddings.detach().cpu()#.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_docs(batch_size=2, doc_path):\n",
    "    \"\"\"Generate batches of documents from the WT collection. Creats a global dict of ids to doc ids.\"\"\"\n",
    "    global c\n",
    "    c = 0\n",
    "    global ids\n",
    "    ids = {}\n",
    "    batch = []\n",
    "    for filename in os.listdir(doc_path):\n",
    "        with open(doc_path+\"/\"+filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                l = json.loads(line)\n",
    "                for doc in l:\n",
    "                    c+=1\n",
    "                    if len(batch) == batch_size:\n",
    "                        full_batch = batch\n",
    "                        batch  = []\n",
    "                        batch.append(doc[\"contents\"])\n",
    "                        yield full_batch\n",
    "                    else:\n",
    "                        batch.append(doc[\"contents\"])\n",
    "                    ids[c]= doc[\"id\"]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(batch_size, num_docs, save_every):\n",
    "    \"\"\"create embeddings for docs in batches and save in batches\"\"\"\n",
    "    def save_embs(embs, c, save_every):\n",
    "        embs = torch.cat(embs)\n",
    "        embs.save(f\"../data/index/e5/e5_embeddings_{c}.pt\")\n",
    "        logger.info(f\"Saved embeddings for {c*save_every} documents\")\n",
    "\n",
    "    c = 0\n",
    "    embs = []\n",
    "    for batch in tqdm(gen_docs(batch_size=batch_size), total=(int(num_docs/batch_size))):\n",
    "        embeddings = calc_embeddings(batch)\n",
    "        embs.append(embeddings)\n",
    "\n",
    "        if len(embs) >= save_every:\n",
    "            save_embs(embs, c, save_every)\n",
    "            c+=1\n",
    "            embs = []\n",
    "\n",
    "    save_embs(embs, c, save_every)\n",
    "    logger.info(f\"Done with encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index\n",
    "def create_index(index_dir, size=384):\n",
    "    \"\"\"create index from embedding parts\"\"\"\n",
    "    files = os.listdir(index_dir)\n",
    "\n",
    "    index = faiss.IndexFlatL2(size)   # build the index\n",
    "    print(index.is_trained)\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".pt\"):\n",
    "            index.add(torch.load(index_dir+\"/\"+file)) \n",
    "    index.save(index_dir+\"/e5.index\")\n",
    "\n",
    "\n",
    "def load_index(index_dir):\n",
    "    \"\"\"load faiss index\"\"\"\n",
    "    index = faiss.read_index(index_dir+\"/e5.index\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results\n",
    "def write_trec(topics, I, D, ids):\n",
    "    \"\"\"write results as trec\"\"\"\n",
    "    with open(\"../results/trec/e5.WT\", \"w\") as f:\n",
    "        for qid, query, results in zip(topics[\"qid\"].to_list(), I, D):\n",
    "            for rank, (doc_id, distance) in enumerate(zip(query, results)):\n",
    "                f.write(\"{} Q0 {} {} {} IRC-e5\\n\".format(qid, ids[doc_id], rank, 10-distance))\n",
    "                # print(qid, \"Q0\", ids[doc_id], rank, 10-distance, \"IRC-e5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics\n",
    "\n",
    "topics = pt.io.read_topics(\"../\" + config[\"WT\"][\"train\"][\"topics\"])  # load topics\n",
    "query_embedding = calc_embeddings(topics[\"query\"], mode='query')     # encode query embeddings\n",
    "\n",
    "index = load_index(index_dir)                                        # load index\n",
    "D, I = index.search(query_embedding[:2], k = 1000)                   # actual search\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
