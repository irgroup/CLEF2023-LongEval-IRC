{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "from src.exp_logger import logger\n",
    "\n",
    "import pyterrier as pt  # type: ignore\n",
    "import json\n",
    "from src.load_index import setup_system\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index with  1570734 documents.\n"
     ]
    }
   ],
   "source": [
    "index, topics, qrels = setup_system(\"WT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "id_no = {}\n",
    "meta = index.getMetaIndex()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        id_no[len(id_no)] = meta.getItem(\"docno\", len(id_no))\n",
    "    except:\n",
    "        print(\"Done\")\n",
    "        break\n",
    "\n",
    "no_id = {v: k for k, v in id_no.items()}\n",
    "\n",
    "\n",
    "def make_passages(doc):\n",
    "    passages = doc.split(\"\\n\")\n",
    "\n",
    "    # remove short passages\n",
    "    passages = [passage for passage in passages if len(passage.strip().split(\" \"))>=3]\n",
    "\n",
    "    # split into chuncs of 50 words\n",
    "    result = []\n",
    "    gathered_passages = \"\"\n",
    "\n",
    "    for passage in passages:\n",
    "        if len(gathered_passages.split(\" \")) + len(passage.split(\" \")) <= 65:\n",
    "            gathered_passages = gathered_passages  + \" \" + passage\n",
    "            # print(\"Gathering further\")\n",
    "        elif len(gathered_passages.split(\" \")) + len(passage.split(\" \")) > 65:\n",
    "            if len(gathered_passages.split(\" \")) == 0:\n",
    "                result.append(passage.strip())\n",
    "            else:\n",
    "                result.append(gathered_passages.strip())\n",
    "                # print(len(gathered_passages.split(\" \")))\n",
    "\n",
    "                gathered_passages = passage\n",
    "    return result\n",
    "\n",
    "\n",
    "def clean(row):\n",
    "    doc = row[\"doc\"]\n",
    "    doc = doc.replace(row[\"docno\"], \"\")\n",
    "    result = make_passages(doc)\n",
    "    return result\n",
    "\n",
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    return max(list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_passages():\n",
    "    rels = topics.merge(qrels[qrels[\"label\"]>=1], on=\"qid\")\n",
    "\n",
    "    for _, query in tqdm(topics.iterrows(), total=len(topics)):\n",
    "        qid = query[\"qid\"]\n",
    "        query = query[\"query\"]\n",
    "\n",
    "        ##### Get relevant passages #####\n",
    "        rel_docs = rels[rels[\"qid\"] == qid][\"docno\"].tolist()  # get relevant docs\n",
    "        if not rel_docs:\n",
    "            logger.warning(f\"Skipping {qid}: `{query}`, not relevant docs found\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        for docno in rel_docs:\n",
    "            docid = no_id[docno]\n",
    "            doc = index.getMetaIndex().getItem(\"text\", docid)\n",
    "            cleaned_doc = doc.replace(docno, \" \").strip()\n",
    "            doc_pass = make_passages(cleaned_doc)\n",
    "            logger.info(f\"Found {len(doc_pass)} passages for {docno}\")\n",
    "        \n",
    "            with open(\"data/passages/t5/WT-relevant-passages.jsonl\", \"a+\") as f:\n",
    "                for passage in doc_pass:\n",
    "                    json.dump({\"qid\": qid, \"docno\": docno, \"passage\": passage}, f)\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_relevant_passages():\n",
    "    bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "    for _, query in tqdm(topics.iterrows(), total=len(topics)):\n",
    "        qid = query[\"qid\"]\n",
    "        base = bm25(topics[topics[\"qid\"]==qid])  # baseline\n",
    "        gradet = base.merge(qrels, on=[\"qid\", \"docno\"])  # add grading    \n",
    "        not_relevant_docs = gradet[gradet[\"label\"]==0][\"docno\"].tolist()  # get not rel docs\n",
    "        logger.info(f\"Found {len(not_relevant_docs)} graded and not relevant docs for {qid}\")\n",
    "\n",
    "        for docno in not_relevant_docs:\n",
    "            docid = no_id[docno]\n",
    "            doc = index.getMetaIndex().getItem(\"text\", docid)\n",
    "            cleaned_doc = doc.replace(docno, \" \").strip()\n",
    "            doc_pass = make_passages(cleaned_doc)\n",
    "            logger.info(f\"Found {len(doc_pass)} passages for {docno}\")\n",
    "        \n",
    "            with open(\"data/passages/t5/WT-not-relevant-passages.jsonl\", \"a+\") as f:\n",
    "                for passage in doc_pass:\n",
    "                    json.dump({\"qid\": qid, \"docno\": docno, \"passage\": passage}, f)\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/672 [00:00<00:05, 119.22it/s][2023-05-06 10:47:04][WARNING] src.exp_logger: Skipping q062216451: `chateau cathare`, not relevant docs found\n",
      "  4%|▍         | 27/672 [00:00<00:04, 134.68it/s][2023-05-06 10:47:04][WARNING] src.exp_logger: Skipping q0622724: `convert video to mp3`, not relevant docs found\n",
      " 14%|█▍        | 95/672 [00:00<00:04, 122.09it/s][2023-05-06 10:47:05][WARNING] src.exp_logger: Skipping q062222125: `least expensive electric car`, not relevant docs found\n",
      " 16%|█▌        | 108/672 [00:00<00:04, 117.17it/s][2023-05-06 10:47:05][WARNING] src.exp_logger: Skipping q06223848: `water meter`, not relevant docs found\n",
      " 18%|█▊        | 120/672 [00:00<00:04, 116.92it/s][2023-05-06 10:47:05][WARNING] src.exp_logger: Skipping q06223898: `bushcraft knife`, not relevant docs found\n",
      " 27%|██▋       | 179/672 [00:01<00:04, 104.12it/s][2023-05-06 10:47:06][WARNING] src.exp_logger: Skipping q062218529: `water collector`, not relevant docs found\n",
      " 30%|███       | 204/672 [00:01<00:04, 110.50it/s][2023-05-06 10:47:06][WARNING] src.exp_logger: Skipping q062219081: `waterfowl`, not relevant docs found\n",
      " 41%|████      | 273/672 [00:02<00:03, 122.49it/s][2023-05-06 10:47:07][WARNING] src.exp_logger: Skipping q06229033: `car size`, not relevant docs found\n",
      " 45%|████▍     | 301/672 [00:02<00:03, 117.99it/s][2023-05-06 10:47:07][WARNING] src.exp_logger: Skipping q062210081: `consumption water home`, not relevant docs found\n",
      " 57%|█████▋    | 381/672 [00:03<00:02, 113.45it/s][2023-05-06 10:47:07][WARNING] src.exp_logger: Skipping q062212442: `veal shoulder`, not relevant docs found\n",
      " 61%|██████    | 411/672 [00:03<00:02, 128.43it/s][2023-05-06 10:47:08][WARNING] src.exp_logger: Skipping q062214218: `the curtained redoubt`, not relevant docs found\n",
      " 67%|██████▋   | 449/672 [00:03<00:01, 113.51it/s][2023-05-06 10:47:08][WARNING] src.exp_logger: Skipping q062215377: `bordeaux ring ring road dir`, not relevant docs found\n",
      " 86%|████████▌ | 579/672 [00:04<00:00, 129.47it/s][2023-05-06 10:47:09][WARNING] src.exp_logger: Skipping q062220780: `used car rental`, not relevant docs found\n",
      " 90%|█████████ | 606/672 [00:05<00:00, 118.63it/s][2023-05-06 10:47:09][WARNING] src.exp_logger: Skipping q062222134: `most reliable cars`, not relevant docs found\n",
      " 94%|█████████▍| 632/672 [00:05<00:00, 122.21it/s][2023-05-06 10:47:09][WARNING] src.exp_logger: Skipping q062223487: `gateau leger`, not relevant docs found\n",
      "[2023-05-06 10:47:09][WARNING] src.exp_logger: Skipping q062223622: `weekly horoscope of the verse`, not relevant docs found\n",
      "100%|██████████| 672/672 [00:05<00:00, 120.43it/s]\n",
      "100%|██████████| 672/672 [16:07<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(\"WARNING\")\n",
    "\n",
    "relevant_passages()\n",
    "\n",
    "not_relevant_passages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
