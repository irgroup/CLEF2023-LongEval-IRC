{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Fold cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exp_logger import logger\n",
    "from src.load_index import setup_system\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import yaml  # type: ignore\n",
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"settings.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index with  1570734 documents.\n"
     ]
    }
   ],
   "source": [
    "index, topics, qrels = setup_system(\"WT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoT5Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        text = f'Query: {sample[0]} Document: {sample[1]} Relevant:'\n",
    "        return {\n",
    "          'text': text,\n",
    "          'labels': sample[2],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample topics just in case\n",
    "topics = topics.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "relevant = pd.read_json(\"data/passages/t5/WT-relevant-passages.jsonl\", lines=True)\n",
    "not_relevant = pd.read_json(\"data/passages/t5/WT-not-relevant-passages.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train, test):\n",
    "    # Load data\n",
    "    ## topics\n",
    "    train_topics = topics.iloc[train]\n",
    "    test_topics = topics.iloc[test]\n",
    "    \n",
    "    ## qrels\n",
    "    test_qrels = qrels[qrels[\"qid\"].isin(test_topics[\"qid\"])]\n",
    "\n",
    "    ## passages\n",
    "    train_relevant = relevant[relevant[\"qid\"].isin(train_topics[\"qid\"])]\n",
    "    train_not_relevant = not_relevant[not_relevant[\"qid\"].isin(train_topics[\"qid\"])]\n",
    "\n",
    "    ## samples\n",
    "    train_samples = []\n",
    "    train_relevant = train_relevant.merge(train_topics, on=\"qid\", how=\"left\")\n",
    "    train_relevant[\"sample\"] = train_relevant.apply(lambda x: [x[\"query\"], x[\"passage\"], \"true\"], axis=1)\n",
    "    train_samples.extend(train_relevant[\"sample\"].to_list())\n",
    "\n",
    "    train_not_relevant = train_not_relevant.merge(train_topics, on=\"qid\", how=\"left\")\n",
    "    train_not_relevant[\"sample\"] = train_not_relevant.apply(lambda x: [x[\"query\"], x[\"passage\"], \"false\"], axis=1)\n",
    "    train_samples.extend(train_not_relevant[\"sample\"].to_list())\n",
    "    \n",
    "    ## shuffle\n",
    "    random.Random(42).shuffle(train_samples)\n",
    "    return train_samples, test_topics, test_qrels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(samples):\n",
    "    # cuda\n",
    "    device = torch.device('cuda')\n",
    "    torch.manual_seed(123)\n",
    "    \n",
    "    # settings\n",
    "    base_model = \"castorini/monoT5-base-msmarco\"\n",
    "    output_model_path = \"data/models/monoT5-fold/checkpoints/\"\n",
    "    save_every_n_steps = 1000\n",
    "    logging_steps = 100\n",
    "    per_device_train_batch_size = 6\n",
    "    gradient_accumulation_steps = 16\n",
    "    learning_rate = 3e-4  # original\n",
    "    epochs = 10\n",
    "\n",
    "    # model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(base_model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "\n",
    "    train_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_model_path,\n",
    "        do_train=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps =save_every_n_steps, \n",
    "        logging_steps=logging_steps,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=5e-5,\n",
    "        num_train_epochs=1,\n",
    "        warmup_steps=0,\n",
    "        # warmup_steps=1000,\n",
    "        adafactor=True,\n",
    "        seed=1,\n",
    "        disable_tqdm=False,\n",
    "        load_best_model_at_end=False,\n",
    "        predict_with_generate=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    "    \n",
    "    def smart_batching_collate_text_only(batch):\n",
    "        texts = [example['text'] for example in batch]\n",
    "        tokenized = tokenizer(texts, padding=True, truncation='longest_first', return_tensors='pt', max_length=512)\n",
    "        tokenized['labels'] = tokenizer([example['labels'] for example in batch], return_tensors='pt')['input_ids']\n",
    "\n",
    "        for name in tokenized:\n",
    "            tokenized[name] = tokenized[name].to(device)\n",
    "\n",
    "        return tokenized\n",
    "    \n",
    "\n",
    "    dataset_train = MonoT5Dataset(samples)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=dataset_train,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=smart_batching_collate_text_only,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(output_model_path.replace(\"checkpoints\", \"monoT5\"))\n",
    "    trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system():\n",
    "    model_path = \"data/models/monoT5-fold/monoT5/\"\n",
    "\n",
    "    bm25 = pt.BatchRetrieve(\n",
    "        index, wmodel=\"BM25\", verbose=True, metadata=[\"docno\", \"text\"]\n",
    "    ).parallel(6)\n",
    "\n",
    "    monoT5 = MonoT5ReRanker(verbose=True, batch_size=8, model=model_path)\n",
    "    \n",
    "    mono_pipeline = bm25 >> pt.text.get_text(index, \"text\") >>  monoT5 \n",
    "    return mono_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68271\n",
      "68271 135 2062\n",
      "70720\n",
      "70720 135 1803\n",
      "70107\n",
      "70107 134 1879\n",
      "70079\n",
      "70079 134 1947\n",
      "70207\n",
      "70207 134 1965\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "c = 0\n",
    "for train, test in kf.split(topics):\n",
    "    # Load data\n",
    "    train_samples, test_topics, test_qrels = load_data(train, test)\n",
    "    print(len(train_samples), len(test_topics), len(test_qrels))\n",
    "\n",
    "    # Fit model\n",
    "    fit_model(train_samples)\n",
    "\n",
    "    # Create run\n",
    "    system = get_system()\n",
    "\n",
    "    c+=1\n",
    "    run_tag = \"monoT5-f\"+c\n",
    "\n",
    "    pt.io.write_results(system(topics), config[\"results_path\"]+\"fold/\" + run_tag)\n",
    "    print(\"Run written to\", config[\"results_path\"]+\"fold/\" + run_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
