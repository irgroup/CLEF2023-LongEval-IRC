{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./index_t1\n",
    "# indexer = pt.TRECCollectionIndexer(\"data/publish/English/Documents/Trec/\", blocks=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_paths_t1 = [os.path.join(dataset_path_t1, path) for path in os.listdir(dataset_path_t1)]\n",
    "# indexref_t1 = indexer.index(doc_paths_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_t1 = pt.IndexFactory.of(\"./index_t1\")\n",
    "\n",
    "query_path_t1 = \"data/publish/English/Queries/train.trec\"\n",
    "topics_t1 = pt.io.read_topics(query_path_t1)\n",
    "\n",
    "qrels_t1 = pt.io.read_qrels(\"data/publish/French/Qrels/train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1570734\n",
      "Number of terms: 3694081\n",
      "Number of postings: 433928454\n",
      "Number of fields: 0\n",
      "Number of tokens: 777790536\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_topics, validation_topics, test_topics = np.split(\n",
    "            topics_t1, [int(0.6 * len(topics_t1)), int(0.8 * len(topics_t1))]\n",
    "        )\n",
    "train_qrels, validation_qrels, test_qrels = np.split(\n",
    "            qrels_t1, [int(0.6 * len(qrels_t1)), int(0.8 * len(qrels_t1))]\n",
    "        )\n",
    "\n",
    "\n",
    "print(index_t1.getCollectionStatistics().toString())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LETOR import LETOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letor = LETOR(index_t1, query_path_t1)\n",
    "\n",
    "def _features(row):\n",
    "    docid = row[\"docid\"]\n",
    "    \n",
    "    queryid = row[\"qid\"]\n",
    "    features = row[\"features\"]  # get the features from the previous stage\n",
    "\n",
    "    letor_features = letor.get_features_letor(queryid, docid)\n",
    "\n",
    "    return np.append(features, letor_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = pt.BatchRetrieve(index_t1, wmodel=\"TF_IDF\")\n",
    "BM25 = pt.BatchRetrieve(index_t1, wmodel=\"BM25\")\n",
    "PL2 = pt.BatchRetrieve(index_t1, wmodel=\"PL2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbr = pt.FeaturesBatchRetrieve(index_t1, \n",
    "                             controls = {\"wmodel\": \"BM25\"}, \n",
    "                             features=[\n",
    "                                      \"WMODEL:Tf\",\n",
    "                                      \"WMODEL:TF_IDF\", \n",
    "                                      \"WMODEL:BM25\", \n",
    "                                      ]\n",
    "                             ) >> pt.apply.doc_features(_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the regressor object.\n",
    "rf = RandomForestRegressor(n_estimators=400)\n",
    "rf_pipe = fbr >> pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(train_topics, train_qrels)\n",
    "print(\"Random Forest done\")\n",
    "\n",
    "# Logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr_pipe = fbr >> pt.ltr.apply_learned_model(lr)\n",
    "lr_pipe.fit(train_topics, train_qrels)\n",
    "print(\"Logistic Regression done\")\n",
    "\n",
    "# Support Vector regression\n",
    "svr = svm.SVR()\n",
    "svr_pipe = fbr >> pt.ltr.apply_learned_model(svr)\n",
    "svr_pipe.fit(train_topics, train_qrels)\n",
    "print(\"Support Vector Regression done\")\n",
    "\n",
    "# LambdaMART\n",
    "lmart_x = xgb.sklearn.XGBRanker(objective='rank:ndcg',\n",
    "    learning_rate=0.1,\n",
    "    gamma=1.0,\n",
    "    min_child_weight=0.1,\n",
    "    max_depth=6,\n",
    "    verbose=2,\n",
    "    random_state=42)\n",
    "\n",
    "lmart_xgb_pipe = fbr >> pt.ltr.apply_learned_model(lmart_x, form=\"ltr\")\n",
    "lmart_xgb_pipe.fit(train_topics, train_qrels, validation_topics, validation_qrels)\n",
    "print(\"LambdaMART done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = [TF_IDF, BM25, PL2, rf_pipe, lr_pipe, svr_pipe, lmart_xgb_pipe]\n",
    "names  = [\"TF-IDF\", \"BM25\", \"PL2\", \"Random Forest\", \"Logistic Regression\", \"Support Vector Regression\", \"LambdaMART\"]\n",
    "\n",
    "results = pt.Experiment(\n",
    "    systems,\n",
    "    test_topics,\n",
    "    test_qrels,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"P_20\", \"ndcg_cut_20\"],\n",
    "    baseline=0,\n",
    "    names=names,\n",
    "    correction='bonferroni',\n",
    "    verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de799d42c25ddca237967bbfe557600abd5e50d5127f08aa58fde1b67499fc96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
