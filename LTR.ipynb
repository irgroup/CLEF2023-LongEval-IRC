{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./index_t1/*\n",
    "# indexer = pt.TRECCollectionIndexer(\"./index_t1\", blocks=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_paths_t1 = [os.path.join(\"data/publish/English/Documents/Trec/\", path) for path in os.listdir(\"data/publish/English/Documents/Trec/\")]\n",
    "# indexref_t1 = indexer.index(doc_paths_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_t1 = pt.IndexFactory.of(\"./index_t1\")\n",
    "\n",
    "query_path_t1 = \"data/publish/English/Queries/train.trec\"\n",
    "topics_t1 = pt.io.read_topics(query_path_t1)\n",
    "\n",
    "qrels_t1 = pt.io.read_qrels(\"data/publish/French/Qrels/train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1570734\n",
      "Number of terms: 3694081\n",
      "Number of postings: 433928454\n",
      "Number of fields: 0\n",
      "Number of tokens: 777790536\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_topics, validation_topics, test_topics = np.split(\n",
    "            topics_t1, [int(0.6 * len(topics_t1)), int(0.8 * len(topics_t1))]\n",
    "        )\n",
    "train_qrels, validation_qrels, test_qrels = np.split(\n",
    "            qrels_t1, [int(0.6 * len(qrels_t1)), int(0.8 * len(qrels_t1))]\n",
    "        )\n",
    "\n",
    "\n",
    "print(index_t1.getCollectionStatistics().toString())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LETOR import LETOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letor = LETOR(index_t1, query_path_t1)\n",
    "\n",
    "def _features(row):\n",
    "    docid = row[\"docid\"]\n",
    "    \n",
    "    queryid = row[\"qid\"]\n",
    "    features = row[\"features\"]  # get the features from the previous stage\n",
    "\n",
    "    letor_features = letor.get_features_letor(queryid, docid)\n",
    "\n",
    "    return np.append(features, letor_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = pt.BatchRetrieve(index_t1, wmodel=\"TF_IDF\")\n",
    "BM25 = pt.BatchRetrieve(index_t1, wmodel=\"BM25\")\n",
    "PL2 = pt.BatchRetrieve(index_t1, wmodel=\"PL2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbr = pt.FeaturesBatchRetrieve(index_t1, \n",
    "                             controls = {\"wmodel\": \"BM25\"}, \n",
    "                             features=[\n",
    "                                      \"WMODEL:Tf\",\n",
    "                                      \"WMODEL:TF_IDF\", \n",
    "                                      \"WMODEL:BM25\", \n",
    "                                      ]\n",
    "                             ) >> pt.apply.doc_features(_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfbr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_topics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/apply_base.py:172\u001b[0m, in \u001b[0;36mApplyDocFeatureTransformer.transform\u001b[0;34m(self, inputRes)\u001b[0m\n\u001b[1;32m    170\u001b[0m     outputRes[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m outputRes\u001b[39m.\u001b[39mprogress_apply(fn, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     outputRes[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m outputRes\u001b[39m.\u001b[39;49mapply(fn, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m outputRes\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36m_features\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m queryid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# get the features from the previous stage\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m letor_features \u001b[38;5;241m=\u001b[39m \u001b[43mletor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_features_letor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueryid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mappend(features, letor_features)\n",
      "File \u001b[0;32m~/dev/LongEval/src/LETOR.py:156\u001b[0m, in \u001b[0;36mLETOR.get_features_letor\u001b[0;34m(self, query_id, doc_id)\u001b[0m\n\u001b[1;32m    130\u001b[0m stream_length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_length_11(doc_id)\n\u001b[1;32m    132\u001b[0m \u001b[39m# prepare features\u001b[39;00m\n\u001b[1;32m    133\u001b[0m features \u001b[39m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovered_query_term_number_1(query_id, doc_id),\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovered_query_term_ratio_6(query_id, doc_id),\n\u001b[1;32m    136\u001b[0m     stream_length,\n\u001b[1;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midf_inverse_document_frequency_16(idfs),\n\u001b[1;32m    138\u001b[0m     \u001b[39m# Tf\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[39msum\u001b[39m(tfs),\n\u001b[1;32m    140\u001b[0m     \u001b[39mmin\u001b[39m(tfs),\n\u001b[1;32m    141\u001b[0m     \u001b[39mmax\u001b[39m(tfs),\n\u001b[1;32m    142\u001b[0m     np\u001b[39m.\u001b[39mmean(tfs),\n\u001b[1;32m    143\u001b[0m     np\u001b[39m.\u001b[39mvar(tfs),\n\u001b[1;32m    144\u001b[0m     \u001b[39msum\u001b[39m(tfs) \u001b[39m/\u001b[39m stream_length,\n\u001b[1;32m    145\u001b[0m     \u001b[39mmin\u001b[39m(tfs) \u001b[39m/\u001b[39m stream_length,\n\u001b[1;32m    146\u001b[0m     \u001b[39mmax\u001b[39m(tfs) \u001b[39m/\u001b[39m stream_length,\n\u001b[1;32m    147\u001b[0m     np\u001b[39m.\u001b[39mmean(tfs) \u001b[39m/\u001b[39m stream_length,\n\u001b[1;32m    148\u001b[0m     np\u001b[39m.\u001b[39mvar(tfs) \u001b[39m/\u001b[39m stream_length,\n\u001b[1;32m    149\u001b[0m     \u001b[39m# Tf-idf\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[39msum\u001b[39m(tf_idfs),\n\u001b[1;32m    151\u001b[0m     \u001b[39mmin\u001b[39m(tf_idfs),\n\u001b[1;32m    152\u001b[0m     \u001b[39mmax\u001b[39m(tf_idfs),\n\u001b[1;32m    153\u001b[0m     np\u001b[39m.\u001b[39mmean(tf_idfs),\n\u001b[1;32m    154\u001b[0m     np\u001b[39m.\u001b[39mvar(tf_idfs),\n\u001b[1;32m    155\u001b[0m     \u001b[39m# bool\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboolean_model_96(query_id, doc_id),\n\u001b[1;32m    157\u001b[0m     \u001b[39m# vector_space_model_101\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# BM25_106\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39m# LMIRABS_111\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[39m# LMIRACLM_116\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[39m# LMIRADIR_121\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# Number of slash in URL\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# Length of URL\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Inlink number\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# Outlink number\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# PageRank\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# SiteRank\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# QualityScore\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39m# QualityScore2\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[39m# Query-url click count\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39m# url click count\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39m# url dwell time\u001b[39;00m\n\u001b[1;32m    173\u001b[0m ]\n\u001b[1;32m    174\u001b[0m \u001b[39mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m~/dev/LongEval/src/LETOR.py:256\u001b[0m, in \u001b[0;36mLETOR.boolean_model_96\u001b[0;34m(self, query_id, doc_id)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m\"\"\"Boolean model.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m    int: 1 if all query terms are in the document, 0 otherwise.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m query_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_query_tokens(query_id)\n\u001b[0;32m--> 256\u001b[0m doc_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_doc_tokens(doc_id)\n\u001b[1;32m    257\u001b[0m covered_query_term_number \u001b[39m=\u001b[39m query_tokens\u001b[39m.\u001b[39mintersection(doc_tokens)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m covered_query_term_number \u001b[39m==\u001b[39m query_tokens:\n",
      "File \u001b[0;32m~/dev/LongEval/src/LETOR.py:96\u001b[0m, in \u001b[0;36mLETOR.get_doc_tokens\u001b[0;34m(self, doc_id)\u001b[0m\n\u001b[1;32m     94\u001b[0m posting \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdoc_di\u001b[39m.\u001b[39mgetPostings(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdoc_doi\u001b[39m.\u001b[39mgetDocumentEntry(doc_id))\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m posting:\n\u001b[0;32m---> 96\u001b[0m     stemm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc_lex\u001b[39m.\u001b[39;49mgetLexiconEntry(t\u001b[39m.\u001b[39;49mgetId())\u001b[39m.\u001b[39mgetKey()\n\u001b[1;32m     97\u001b[0m     doc_tokens\u001b[39m.\u001b[39madd(stemm)\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m doc_tokens\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fbr.transform(validation_topics.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:   0%|          | 0/1 [01:59<?, ?system/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfbr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_topics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_qrels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecip_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/pipelines.py:450\u001b[0m, in \u001b[0;36mExperiment\u001b[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m save_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     save_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir, \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.res.gz\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 450\u001b[0m time, evalMeasuresDict \u001b[39m=\u001b[39m _run_and_evaluate(\n\u001b[1;32m    451\u001b[0m     system, topics, qrels, eval_metrics, \n\u001b[1;32m    452\u001b[0m     perquery\u001b[39m=\u001b[39;49mperquery \u001b[39mor\u001b[39;49;00m baseline \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m    453\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m    454\u001b[0m     backfill_qids\u001b[39m=\u001b[39;49mall_topic_qids \u001b[39mif\u001b[39;49;00m perquery \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    455\u001b[0m     save_file\u001b[39m=\u001b[39;49msave_file,\n\u001b[1;32m    456\u001b[0m     save_mode\u001b[39m=\u001b[39;49msave_mode,\n\u001b[1;32m    457\u001b[0m     pbar\u001b[39m=\u001b[39;49mpbar)\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m baseline \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     evalDictsPerQ\u001b[39m.\u001b[39mappend(evalMeasuresDict)\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/pipelines.py:170\u001b[0m, in \u001b[0;36m_run_and_evaluate\u001b[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39melif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39m#transformer, evaluate all queries at once\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     starttime \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 170\u001b[0m     res \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    171\u001b[0m     endtime \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    172\u001b[0m     runtime \u001b[39m=\u001b[39m  (endtime \u001b[39m-\u001b[39m starttime) \u001b[39m*\u001b[39m \u001b[39m1000.\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pyterrier/apply_base.py:172\u001b[0m, in \u001b[0;36mApplyDocFeatureTransformer.transform\u001b[0;34m(self, inputRes)\u001b[0m\n\u001b[1;32m    170\u001b[0m     outputRes[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m outputRes\u001b[39m.\u001b[39mprogress_apply(fn, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     outputRes[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m outputRes\u001b[39m.\u001b[39;49mapply(fn, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m outputRes\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/MA/lib/python3.9/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36m_features\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m queryid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# get the features from the previous stage\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m letor_features \u001b[38;5;241m=\u001b[39m \u001b[43mletor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_features_letor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueryid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mappend(features, letor_features)\n",
      "File \u001b[0;32m~/dev/LongEval/src/LETOR.py:126\u001b[0m, in \u001b[0;36mLETOR.get_features_letor\u001b[0;34m(self, query_id, doc_id)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_features_letor\u001b[39m(\u001b[39mself\u001b[39m, query_id: \u001b[39mint\u001b[39m, doc_id: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    125\u001b[0m     \u001b[39m# prepare stats\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     tfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_doc_tf(query_id, doc_id)\n\u001b[1;32m    127\u001b[0m     idfs \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39midf(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_query_tokens(query_id)]\n\u001b[1;32m    128\u001b[0m     tf_idfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_idf(tfs, idfs)\n",
      "File \u001b[0;32m~/dev/LongEval/src/LETOR.py:110\u001b[0m, in \u001b[0;36mLETOR.get_doc_tf\u001b[0;34m(self, query_id, doc_id)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mfor\u001b[39;00m posting \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdoc_di\u001b[39m.\u001b[39mgetPostings(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdoc_doi\u001b[39m.\u001b[39mgetDocumentEntry(doc_id)):\n\u001b[1;32m    108\u001b[0m     termid \u001b[39m=\u001b[39m posting\u001b[39m.\u001b[39mgetId()\n\u001b[0;32m--> 110\u001b[0m     lee \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc_lex\u001b[39m.\u001b[39;49mgetLexiconEntry(termid)\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m lee\u001b[39m.\u001b[39mgetKey() \u001b[39min\u001b[39;00m relevant_token:\n\u001b[1;32m    113\u001b[0m         tf\u001b[39m.\u001b[39mappend(posting\u001b[39m.\u001b[39mgetFrequency())\n",
      "File \u001b[0;32mjnius/jnius_export_class.pxi:1177\u001b[0m, in \u001b[0;36mjnius.JavaMultipleMethod.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mjnius/jnius_export_class.pxi:885\u001b[0m, in \u001b[0;36mjnius.JavaMethod.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mjnius/jnius_export_class.pxi:967\u001b[0m, in \u001b[0;36mjnius.JavaMethod.call_method\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mjnius/jnius_conversion.pxi:239\u001b[0m, in \u001b[0;36mjnius.convert_jobject_to_python\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [fbr],\n",
    "    train_topics,\n",
    "    train_qrels,\n",
    "    eval_metrics=[\"map\", \"recip_rank\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q06223196</td>\n",
       "      <td>car shelter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q062228</td>\n",
       "      <td>airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q062287</td>\n",
       "      <td>antivirus comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q06223261</td>\n",
       "      <td>free antivirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q062291</td>\n",
       "      <td>orange antivirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>q062213211</td>\n",
       "      <td>consumption electric car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>q062213307</td>\n",
       "      <td>leg leg leg leg leg leg leg leg leg leg leg le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>q062213401</td>\n",
       "      <td>download video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>q062213479</td>\n",
       "      <td>whitewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>q062213524</td>\n",
       "      <td>employment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qid                                              query\n",
       "0     q06223196                                        car shelter\n",
       "1       q062228                                            airport\n",
       "2       q062287                               antivirus comparison\n",
       "3     q06223261                                     free antivirus\n",
       "4       q062291                                   orange antivirus\n",
       "..          ...                                                ...\n",
       "398  q062213211                           consumption electric car\n",
       "399  q062213307  leg leg leg leg leg leg leg leg leg leg leg le...\n",
       "400  q062213401                                     download video\n",
       "401  q062213479                                         whitewater\n",
       "402  q062213524                                         employment\n",
       "\n",
       "[403 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LambdaMART created\n",
      "LambdaMART pipeline created\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m lmart_xgb_pipe \u001b[38;5;241m=\u001b[39m fbr \u001b[38;5;241m>>\u001b[39m pt\u001b[38;5;241m.\u001b[39mltr\u001b[38;5;241m.\u001b[39mapply_learned_model(lmart_x, form\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mltr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambdaMART pipeline created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mlmart_xgb_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_qrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_qrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambdaMART done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# Create the regressor object.\n",
    "# rf = RandomForestRegressor(n_estimators=10, max_depth=2, n_jobs=12, random_state=42, verbose=3, max_samples=100)\n",
    "# print(\"Random Forest created\")\n",
    "# rf_pipe = fbr >> pt.ltr.apply_learned_model(rf)\n",
    "# print(\"Random Forest pipeline created\")\n",
    "# rf_pipe.fit(train_topics, train_qrels)\n",
    "# print(\"Random Forest done\")\n",
    "\n",
    "\n",
    "# # Logistic regression\n",
    "# lr = LogisticRegression(random_state=42, verbose=3)\n",
    "# lr_pipe = fbr >> pt.ltr.apply_learned_model(lr)\n",
    "# lr_pipe.fit(train_topics, train_qrels, validation_topics, validation_qrels)\n",
    "# print(\"Logistic Regression done\")\n",
    "\n",
    "\n",
    "# # Support Vector regression\n",
    "# svr = svm.SVR(random_state=42, verbose=3)\n",
    "# svr_pipe = fbr >> pt.ltr.apply_learned_model(svr)\n",
    "# svr_pipe.fit(train_topics, train_qrels, validation_topics, validation_qrels)\n",
    "# print(\"Support Vector Regression done\")\n",
    "\n",
    "# LambdaMART\n",
    "lmart_x = xgb.sklearn.XGBRanker(objective='rank:ndcg',\n",
    "    learning_rate=0.1,\n",
    "    gamma=1.0,\n",
    "    min_child_weight=0.1,\n",
    "    max_depth=6,\n",
    "    verbose=2,\n",
    "    random_state=42)\n",
    "print(\"LambdaMART created\")\n",
    "\n",
    "lmart_xgb_pipe = fbr >> pt.ltr.apply_learned_model(lmart_x, form=\"ltr\")\n",
    "print(\"LambdaMART pipeline created\")\n",
    "lmart_xgb_pipe.fit(train_topics, train_qrels, validation_topics, validation_qrels)\n",
    "print(\"LambdaMART done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mWeitere Informationen finden Sie im Jupyter-<a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "systems = [TF_IDF, BM25, PL2, rf_pipe, lr_pipe, svr_pipe, lmart_xgb_pipe]\n",
    "names  = [\"TF-IDF\", \"BM25\", \"PL2\", \"Random Forest\", \"Logistic Regression\", \"Support Vector Regression\", \"LambdaMART\"]\n",
    "\n",
    "results = pt.Experiment(\n",
    "    systems,\n",
    "    test_topics,\n",
    "    test_qrels,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"P_20\", \"ndcg_cut_20\"],\n",
    "    baseline=0,\n",
    "    names=names,\n",
    "    correction='bonferroni',\n",
    "    verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de799d42c25ddca237967bbfe557600abd5e50d5127f08aa58fde1b67499fc96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
